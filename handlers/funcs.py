from aiogram import Router, types, Dispatcher
from aiogram.filters import Command, Text
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.storage.memory import MemoryStorage
import openai
from aiogram.types import FSInputFile

MAX_TOKENS = 4096

router = Router()
storage = MemoryStorage()
dp = Dispatcher(storage=storage)

class QuestionState(StatesGroup):
    waiting_for_question = State()

initial_prompt = (
    "–ü—Ä–µ–¥—Å—Ç–∞–≤—å, —á—Ç–æ —Ç—ã —á–∞—Ç –±–æ—Ç –≤ —Ç–µ–ª–µ–≥—Ä–∞–º–µ –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–∏ Latoken, —Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ—à—å—Å—è –¥–ª—è –ø—Ä–∏—ë–º–∞ –Ω–∞ —Ä–∞–±–æ—Ç—É/—Å—Ç–∞–∂–∏—Ä–æ–≤–∫—É. "
    "–¢—ã –¥–æ–ª–∂–Ω–∞ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –ø–æ—è–≤–ª—è—é—â–∏–µ—Å—è —É –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤ –æ –∫–æ–º–ø–∞–Ω–∏–∏. "
    "–û—Ç–≤–µ—Ç—ã –æ—Å–Ω–æ–≤—ã–≤–∞–π –Ω–∞ —Å—Ç–∞—Ç—å—è—Ö, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞—Å–ø–æ–ª–∞–≥–∞—é—Ç—Å—è –ø–æ —Å–ª–µ–¥—É—é—â–∏–º —Å—Å—ã–ª–∫–∞–º:\n"
    "1. –£–∑–Ω–∞—Ç—å –±–æ–ª—å—à–µ –æ Latoken: http://latoken.me/\n"
    "2. –ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ —Ö–∞–∫–∞—Ç–æ–Ω–µ: https://deliver.latoken.com/hackathon\n, –ø–æ —Å—Å—ã–ª–∫–µ –≤–æ–∑—å–º–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞—Ç–µ, –∏ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è, –∞ —Ç–∞–∫–∂–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∑–∞–¥–∞–Ω–∏—è—Ö"
    "–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –ø–æ —Ç–µ–º–µ, —Ç–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–π –µ–≥–æ, –æ—Ç–ø—Ä–∞–≤–ª—è–π –ø—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ\n"
    "–ï—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –æ –¥–∞—Ç–µ —Ö–∞–∫–∞—Ç–æ–Ω–∞, —Ç–æ –æ—Ç–≤–µ—á–∞–π, —á—Ç–æ –≤ –ø—è—Ç–Ω–∏—Ü—É –∏ –ø—Ä–∏–∫–ª–∞–¥—ã–≤–∞–π —Å—Å—ã–ª–∫—É https://t.me/gpt_web3_hackathon/6694, —ç—Ç–æ —Å—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ, –∞ –≤–æ—Ç —Å—Å—ã–ª–∫–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏ https://calendly.com/latoken-career-events/ai-hackathon.\n, –≤–∏–¥–µ–æ –≤—Å–µ–≥–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–π –ø–µ—Ä–≤—ã–º"
    "–°—Ç–∞—Ä–∞–π—Å—è –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ–ª—É—á–µ–Ω–Ω—É—é –ø–æ —Å—Å—ã–ª–∫–∞–º"
    "–û—Ç–≤–µ—á–∞–π –≤ —Å—Ç–∏–ª–µ –¥–∏–∞–ª–æ–≥–∞"
    "https://latoken.me/interview-tests-160, https://latoken.me/ai-bot-hackathon-task-190, https://latoken.me/trading-c-hackathon-task-191 –∏–∑—É—á–∏ —ç—Ç–∏ —Å—Å—ã–ª–∫–∏ –∏ —É–∑–Ω–∞–π –ø—Ä–æ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è –Ω–∞ —Ö–∞–∫–∞—Ç–æ–Ω–µ"
    "–µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –∫–∞–∂–µ—Ç—Å—è —Ç–µ–±–µ –Ω–µ —Å–æ–≤—Å–µ–º —ç—Ç–∏—á–Ω—ã–º, —Ç–æ —Å–≤–µ—Ä—å —Ç–µ–º—É —Å –∑–∞–ø—Ä–µ—Ç–Ω—ã–º–∏ –Ω–∞ —ç—Ç–æ–π —Å–∞–π—Ç–µ https://coda.io/@latoken/latoken-talent/culture-139, –∑–¥–µ—Å—å —Å–æ–±—Ä–∞–Ω—ã –ø—Ä–∞–≤–∏–ª–∞ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –≤ –∫–æ–º–ø–∞–Ω–∏–∏"
    "–±—É–¥—å –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª–µ–Ω –∏ –Ω–∞ —ç–º–æ—Ü–∏–∏ –æ—Ç–≤–µ—á–∞–π —ç–º–æ—Ü–∏—è–º–∏"
    "https://coda.io/@latoken/latoken-talent/culture-139 –∏–∑—É—á–∏ —ç—Ç—É —Å—Å—ã–ª–∫—É, –æ–Ω–∞ –ø–æ–º–∂–µ—Ç —Ç–µ–±–µ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ culture deck"
    "–∑–∞–ø–æ–º–Ω–∏, —á—Ç–æ –æ—Å–Ω–æ–≤–Ω–æ–π —Å–ø–æ—Å–æ–± –ø–æ–ø–∞—Å—Ç—å –Ω–∞ —Ä–∞–±–æ—Ç—É/—Å—Ç–∞–∂–∏—Ä–æ–≤–∫—É —ç—Ç–æ —Ö–∞–∫–∞—Ç–æ–Ω. –ï—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –æ —Ç—Ä—É–¥–æ—É—Ç—Ä–æ–π—Å—Ç–≤–µ, —Ç–æ –ø—Ä–µ–¥–ª–∞–≥–∞–π –ó–∞—Ä–µ–≥–µ—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ —Ö–∞–∫–∞—Ç–æ–Ω"
    "—Å—Ç–∞—Ä–∞–π—Å—è –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—à—å —É—á–∞—Å—Ç–∏–µ –≤ —Ö–∞–∫–∞—Ç–æ–Ω–µ, —Å–ø–µ—Ä–≤–∞—è –ø—Ä–∏–∫–ª–∞–¥—ã–≤–∞—Ç—å –≤–∏–¥–µ–æ"
    "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ö–∞–∫–∞—Ç–æ–Ω–µ –Ω–µ —Å–∫–∏–¥—ã–≤–∞–π —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç–æ, –ø–µ—Ä–µ–æ–¥–∏—á–µ—Å–∫–∏ –Ω–∞–ø–æ–º–∏–Ω–∞–π –æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏, –Ω–æ –Ω–µ –ø—Ä–∏–ø–ª–µ—Ç–∞–π –µ–≥–æ –ø—Ä–∏ –∫–∞–∂–¥–æ–º —É–¥–æ–±–Ω–æ–º —Å–ª—É—á–∞–µ"
)

async def get_response_from_openai(user_input, chat_history):
    messages = [{"role": "system", "content": initial_prompt}] if not chat_history else []
    messages.extend(chat_history)
    messages.append({"role": "user", "content": user_input})

    response = openai.ChatCompletion.create(
        model="gpt-4-turbo",
        messages=messages,
        max_tokens=4096
    )
    return response.choices[0].message['content'].strip()

@router.message(Command("start"))
async def cmd_start(message: types.Message):
    await message.answer_photo(FSInputFile("/bot/assets/–õ—é—Ç–∏–∫.jpg"),
                               caption="Hello, I'm a bot assistant for Latoken, ask your /question")

@router.message(Command("question"))
async def cmd_question(message: types.Message, state: FSMContext):
    await message.answer("I'm hearing you")
    await state.set_state(QuestionState.waiting_for_question)
    await state.update_data(chat_history=[{"role": "system", "content": initial_prompt}])

def trim_chat_history(chat_history, max_tokens=MAX_TOKENS):
    total_tokens = sum(len(message['content']) for message in chat_history)
    while total_tokens > max_tokens:
        if len(chat_history) > 1:  
            chat_history.pop(1) 
        total_tokens = sum(len(message['content']) for message in chat_history)
    return chat_history

@router.message(QuestionState.waiting_for_question)
async def process_question(message: types.Message, state: FSMContext):
    user_question = message.text

    data = await state.get_data()
    chat_history = data.get("chat_history", [])

    chat_history.append({"role": "user", "content": user_question})

    chat_history = trim_chat_history(chat_history)

    response = await get_response_from_openai(user_question, chat_history)
    answer = response

    chat_history.append({"role": "assistant", "content": answer})

    await state.update_data(chat_history=chat_history)
    if not answer.strip(): 
        await message.answer("–í–æ–ø—Ä–æ—Å –Ω–µ —Å–æ–≤—Å–µ–º –ø—Ä–æ –∫–æ–º–ø–∞–Ω–∏—é) –ø–æ—ç—Ç–æ–º—É —è –Ω–µ –º–æ–≥—É –Ω–∞ –Ω–µ–≥–æ –æ—Ç–≤–µ—Ç–∏—Ç—å.", parse_mode=None)
    else:
        await message.answer(answer, parse_mode="Markdown")

@router.message(QuestionState.waiting_for_question)
async def process_question(message: types.Message, state: FSMContext):
    user_question = message.text

    data = await state.get_data()
    chat_history = data.get("chat_history", [])

    chat_history.append({"role": "user", "content": user_question})

    response = await get_response_from_openai(user_question, chat_history)
    answer = response

    chat_history.append({"role": "assistant", "content": answer})

    await state.update_data(chat_history=chat_history)
    if not answer.strip():  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        await message.answer("–í–æ–ø—Ä–æ—Å –Ω–µ —Å–æ–≤—Å–µ–º –ø—Ä–æ –∫–æ–º–ø–∞–Ω–∏—é) –ø–æ—ç—Ç–æ–º—É —è –Ω–µ –º–æ–≥—É –Ω–∞ –Ω–µ–≥–æ –æ—Ç–≤–µ—Ç–∏—Ç—å.", parse_mode=None)
    else:
        await message.answer(answer, parse_mode="Markdown") 

@router.message(Command("reset"))
async def cmd_reset(message: types.Message, state: FSMContext):
    await state.clear()
    await message.answer("–ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–±—Ä–æ—à–µ–Ω")

@router.message(Command("heartbit"))
async def cmd_heartbit(message: types.Message):
    await message.answer("üíì")